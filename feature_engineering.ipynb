{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading energy data...\n",
      "Loaded 109189 records for 118 households\n",
      "Date range: 2022-01-01 00:00:00 to 2024-09-02 00:00:00\n",
      "Converting time intervals from kWh to kW...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Loading energy data...\")\n",
    "df = pd.read_csv('cleaned_energy_data.csv')\n",
    "df['INTERVAL_DATE'] = pd.to_datetime(df['INTERVAL_DATE'])\n",
    "\n",
    "#time columns\n",
    "time_cols = [col for col in df.columns if '.' in col and '-' in col]\n",
    "all_icps = df['ICP_IDENTIFIER'].unique()\n",
    "\n",
    "print(f\"Loaded {len(df)} records for {len(all_icps)} households\")\n",
    "print(f\"Date range: {df['INTERVAL_DATE'].min()} to {df['INTERVAL_DATE'].max()}\")\n",
    "\n",
    "# Convert time intervals from kWh to kW \n",
    "print(\"Converting time intervals from kWh to kW...\")\n",
    "df.loc[:, time_cols] = df[time_cols] * 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Room data merged successfully.\n",
      "    ICP_IDENTIFIER  Rooms\n",
      "0  0000002795DE203     11\n",
      "1  0000002795DE203     11\n",
      "2  0000002795DE203     11\n",
      "3  0000002795DE203     11\n",
      "4  0000002795DE203     11\n"
     ]
    }
   ],
   "source": [
    "# Load room data from CSV\n",
    "room_data = pd.read_csv('uniflats.csv')\n",
    "room_data.columns = ['Number', 'Street', 'ICP', 'Rooms', 'Corresponding', 'List']\n",
    "\n",
    "# Clean and prepare room data\n",
    "room_data = room_data[['ICP', 'Rooms']].dropna()\n",
    "room_data['ICP'] = room_data['ICP'].astype(str)\n",
    "\n",
    "# Merge with energy data\n",
    "df = df.merge(room_data[['ICP', 'Rooms']], \n",
    "              left_on='ICP_IDENTIFIER', \n",
    "              right_on='ICP', \n",
    "              how='left')\n",
    "\n",
    "# Clean up extra ICP column\n",
    "df = df.drop(columns=['ICP'])\n",
    "print(f\"Room data merged successfully.\")\n",
    "print(df[['ICP_IDENTIFIER', 'Rooms']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weather data...\n",
      "Energy data date range: 2022-01-01 to 2024-09-02\n",
      "Weather data filtered to: 2022-01-01 to 2024-09-02\n",
      "Daily weather data: (976, 15)\n",
      "Merging daily weather data with energy data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather merge complete. Added 8 weather columns\n",
      "Weather columns: ['daily_temp_avg', 'daily_temp_max', 'daily_temp_min', 'RH_mean', 'WINDSPD_mean']...\n",
      "Found 1610 missing weather values\n",
      "Missing weather dates: [datetime.date(2023, 8, 1), datetime.date(2023, 8, 2)]\n",
      "Dropped 230 records with missing weather data\n",
      "Dataset size: 109189 → 108959 records\n",
      "Dataset is now clean with no missing weather values\n",
      "Weather data merge and cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading weather data...\")\n",
    "# Load the daily weather data\n",
    "daily_weather = pd.read_csv('weather_daily_aggregated.csv')\n",
    "daily_weather['DATETIME'] = pd.to_datetime(daily_weather['DATETIME'])\n",
    "daily_weather['DATE'] = daily_weather['DATETIME'].dt.date\n",
    "\n",
    "# Get energy date range \n",
    "energy_start = df['INTERVAL_DATE'].min().date()\n",
    "energy_end = df['INTERVAL_DATE'].max().date()\n",
    "print(f\"Energy data date range: {energy_start} to {energy_end}\")\n",
    "\n",
    "# Filter weather data to match energy date range\n",
    "daily_weather = daily_weather[(daily_weather['DATE'] >= energy_start) & \n",
    "                             (daily_weather['DATE'] <= energy_end)]\n",
    "\n",
    "print(f\"Weather data filtered to: {daily_weather['DATE'].min()} to {daily_weather['DATE'].max()}\")\n",
    "print(f\"Daily weather data: {daily_weather.shape}\")\n",
    "\n",
    "# Add date column to energy data for merging\n",
    "df['DATE'] = df['INTERVAL_DATE'].dt.date\n",
    "\n",
    "# Merge daily weather with energy data  \n",
    "print(\"Merging daily weather data with energy data...\")\n",
    "df = df.merge(daily_weather, on='DATE', how='left')\n",
    "\n",
    "# Check merge success\n",
    "weather_cols = [col for col in df.columns if any(w in col for w in ['daily_temp', 'RH_mean', 'WINDSPD_mean', 'GLOBAL_mean', 'RAIN_sum', 'PRESS_mean'])]\n",
    "print(f\"Weather merge complete. Added {len(weather_cols)} weather columns\")\n",
    "print(f\"Weather columns: {weather_cols[:5]}...\")  # Show first 5 weather columns\n",
    "\n",
    "# Check for missing weather data and clean up\n",
    "missing_weather = df[weather_cols].isnull().sum().sum()\n",
    "if missing_weather > 0:\n",
    "    print(f\"Found {missing_weather} missing weather values\")\n",
    "    \n",
    "    # Show which dates have missing weather data\n",
    "    missing_dates = df[df[weather_cols].isnull().any(axis=1)]['DATE'].unique()\n",
    "    print(f\"Missing weather dates: {sorted(missing_dates)}\")\n",
    "    \n",
    "    # Drop records with missing weather data\n",
    "    records_before = len(df)\n",
    "    df = df.dropna(subset=weather_cols)\n",
    "    records_after = len(df)\n",
    "    \n",
    "    print(f\"Dropped {records_before - records_after} records with missing weather data\")\n",
    "    print(f\"Dataset size: {records_before} → {records_after} records\")\n",
    "    print(\"Dataset is now clean with no missing weather values\")\n",
    "else:\n",
    "    print(\"No missing weather data\")\n",
    "\n",
    "print(\"Weather data merge and cleaning complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALCULATING BASIC POWER METRICS FOR CLUSTERING\n",
      "Using 48 energy columns for power metrics\n",
      "Processing 118 households...\n",
      "Baseload range: 0.00-5.40 kW\n",
      "Peak range: 0.3-55.6 kW\n",
      "Average range: 0.14-18.74 kW\n"
     ]
    }
   ],
   "source": [
    "# Basic Power Metrics for Clustering\n",
    "print(\"CALCULATING BASIC POWER METRICS FOR CLUSTERING\")\n",
    "\n",
    "# Filter to only energy time columns (exclude weather columns)\n",
    "time_cols_energy_only = [col for col in df.columns \n",
    "                        if '.' in col and '-' in col \n",
    "                        and not any(weather_var in col for weather_var in \n",
    "                                   ['TEMP_', 'RH_', 'WINDSPD_', 'WINDIR_', 'GLOBAL_', 'UVA_', 'UVB_', 'RAIN_', 'PRESS_', 'MAXGUST_'])]\n",
    "\n",
    "print(f\"Using {len(time_cols_energy_only)} energy columns for power metrics\")\n",
    "\n",
    "def calculate_household_power_metrics(df, time_cols_energy):\n",
    "    all_households = df['ICP_IDENTIFIER'].unique()\n",
    "    household_metrics = []\n",
    "    \n",
    "    print(f\"Processing {len(all_households)} households...\")\n",
    "    \n",
    "    for i, icp in enumerate(all_households):\n",
    "        \n",
    "        house_data = df[df['ICP_IDENTIFIER'] == icp]\n",
    "        \n",
    "        # Flattening - energy columns only\n",
    "        all_power_values = house_data[time_cols_energy].values.flatten()\n",
    "        all_power_values = all_power_values[~np.isnan(all_power_values)]\n",
    "        \n",
    "        if len(all_power_values) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Core power metrics\n",
    "        baseload = np.percentile(all_power_values, 5)\n",
    "        peak = np.max(all_power_values)\n",
    "        avg_power = np.mean(all_power_values)\n",
    "        median_power = np.median(all_power_values)\n",
    "        power_std = np.std(all_power_values)\n",
    "        \n",
    "        # Key ratios for clustering\n",
    "        peak_to_avg_ratio = peak / avg_power if avg_power > 0 else 0\n",
    "        load_factor = avg_power / peak if peak > 0 else 0\n",
    "        coefficient_of_variation = power_std / avg_power if avg_power > 0 else 0\n",
    "        \n",
    "        # Store metrics\n",
    "        household_metrics.append({\n",
    "            'ICP_IDENTIFIER': icp,\n",
    "            'num_rooms': house_data['Rooms'].iloc[0] if 'Rooms' in house_data.columns else np.nan,\n",
    "            'baseload_kW': baseload,\n",
    "            'peak_kW': peak,\n",
    "            'avg_power_kW': avg_power,\n",
    "            'median_power_kW': median_power,\n",
    "            'std_power_kW': power_std,\n",
    "            'peak_to_avg_ratio': peak_to_avg_ratio,\n",
    "            'load_factor': load_factor,\n",
    "            'coefficient_of_variation': coefficient_of_variation\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(household_metrics)\n",
    "\n",
    "# Calculate metrics\n",
    "household_features = calculate_household_power_metrics(df, time_cols_energy_only)\n",
    "\n",
    "# Quick validation\n",
    "print(f\"Baseload range: {household_features['baseload_kW'].min():.2f}-{household_features['baseload_kW'].max():.2f} kW\")\n",
    "print(f\"Peak range: {household_features['peak_kW'].min():.1f}-{household_features['peak_kW'].max():.1f} kW\")\n",
    "print(f\"Average range: {household_features['avg_power_kW'].min():.2f}-{household_features['avg_power_kW'].max():.2f} kW\")\n",
    "features_step1 = household_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating weather sensitivity features\n",
      "Calculating daily energy consumption...\n",
      "Merged data: 108959 daily records for weather-energy analysis\n",
      "\n",
      " DUNEDIN TEMPERATURE DATA ANALYSIS:\n",
      "  Temperature range: 3.1°C to 25.1°C\n",
      "  Mean temperature: 12.0°C\n",
      "  Median temperature: 12.0°C\n",
      "  Standard deviation: 3.7°C\n",
      "  Analysis period: 969 unique days\n",
      "\n",
      "  CALCULATED TEMPERATURE THRESHOLDS:\n",
      "  Cold threshold: 9.2°C (25th percentile)\n",
      "  Warm threshold: 14.6°C (75th percentile)\n",
      "  Cold days (< 9.2°C): 241 days (24.9%)\n",
      "  Mild days (9.2°C - 14.6°C): 486 days (50.2%)\n",
      "  Warm days (> 14.6°C): 242 days (25.0%)\n",
      "Processing weather sensitivity for 118 households...\n",
      "\n",
      "Weather Sensitivity Summary\n",
      "Weather features calculated for 118 households\n",
      "\n",
      "Temperature Correlation Range: -0.838 to -0.257\n",
      "Heating Sensitivity Range: 0.58 to 200.81 kWh\n",
      "Seasonal Variability Range: 1.29 to 392.71 kWh\n",
      "\n",
      "Weather Sensitivity Patterns:\n",
      "  High temperature sensitivity (|corr| > 0.3): 116 accommodations (98.3%)\n",
      "  High seasonal variation: 59 accommodations (50.0%)\n"
     ]
    }
   ],
   "source": [
    "# Weather Sensitivity Features\n",
    "print(\"Calculating weather sensitivity features\")\n",
    "\n",
    "def calculate_weather_sensitivity_features(df, time_cols_energy):\n",
    "\n",
    "    # Calculate daily energy consumption for each household using Total_Consumption\n",
    "    print(\"Calculating daily energy consumption...\")\n",
    "    df['DATE'] = df['INTERVAL_DATE'].dt.date\n",
    "    daily_energy = df.groupby(['ICP_IDENTIFIER', 'DATE'])['Total_Consumption'].sum().reset_index()\n",
    "    daily_energy.rename(columns={'Total_Consumption': 'daily_total_kWh'}, inplace=True)\n",
    "    \n",
    "    # Get weather columns that are already in df\n",
    "    weather_cols = [col for col in df.columns if any(w in col for w in ['daily_temp', 'RH_mean', 'WINDSPD_mean', 'GLOBAL_mean', 'RAIN_sum', 'PRESS_mean'])]\n",
    "    \n",
    "    # Merge energy with weather (weather is already in df)\n",
    "    weather_daily = df[['DATE'] + weather_cols].drop_duplicates(subset=['DATE'])\n",
    "    daily_merged = daily_energy.merge(weather_daily, on='DATE', how='inner')\n",
    "    \n",
    "    print(f\"Merged data: {len(daily_merged)} daily records for weather-energy analysis\")\n",
    "    \n",
    "    # Calculate temperature thresholds using percentile method\n",
    "    temp_data = daily_merged['daily_temp_avg']\n",
    "    unique_dates = daily_merged['DATE'].nunique()  # unique days only\n",
    "    temp_min = temp_data.min()\n",
    "    temp_max = temp_data.max()\n",
    "    temp_mean = temp_data.mean()\n",
    "    temp_median = temp_data.median()\n",
    "    temp_std = temp_data.std()\n",
    "    \n",
    "    print(f\"\\n DUNEDIN TEMPERATURE DATA ANALYSIS:\")\n",
    "    print(f\"  Temperature range: {temp_min:.1f}°C to {temp_max:.1f}°C\")\n",
    "    print(f\"  Mean temperature: {temp_mean:.1f}°C\")\n",
    "    print(f\"  Median temperature: {temp_median:.1f}°C\")\n",
    "    print(f\"  Standard deviation: {temp_std:.1f}°C\")\n",
    "    print(f\"  Analysis period: {unique_dates} unique days\")\n",
    "    \n",
    "    # Percentile method for thresholds\n",
    "    cold_threshold = np.percentile(temp_data, 25)  # 25th percentile\n",
    "    warm_threshold = np.percentile(temp_data, 75)  # 75th percentile\n",
    "    \n",
    "    print(f\"\\n  CALCULATED TEMPERATURE THRESHOLDS:\")\n",
    "    print(f\"  Cold threshold: {cold_threshold:.1f}°C (25th percentile)\")\n",
    "    print(f\"  Warm threshold: {warm_threshold:.1f}°C (75th percentile)\")\n",
    "    \n",
    "    # Show distribution using unique days only\n",
    "    unique_temp_data = daily_merged.drop_duplicates('DATE')['daily_temp_avg']\n",
    "    cold_days_count = (unique_temp_data < cold_threshold).sum()\n",
    "    mild_days_count = ((unique_temp_data >= cold_threshold) & (unique_temp_data <= warm_threshold)).sum()\n",
    "    warm_days_count = (unique_temp_data > warm_threshold).sum()\n",
    "    \n",
    "    print(f\"  Cold days (< {cold_threshold:.1f}°C): {cold_days_count} days ({cold_days_count/len(unique_temp_data)*100:.1f}%)\")\n",
    "    print(f\"  Mild days ({cold_threshold:.1f}°C - {warm_threshold:.1f}°C): {mild_days_count} days ({mild_days_count/len(unique_temp_data)*100:.1f}%)\")\n",
    "    print(f\"  Warm days (> {warm_threshold:.1f}°C): {warm_days_count} days ({warm_days_count/len(unique_temp_data)*100:.1f}%)\")\n",
    "    \n",
    "    # Calculate weather sensitivity for each household\n",
    "    all_households = daily_merged['ICP_IDENTIFIER'].unique()\n",
    "    weather_features = []\n",
    "    \n",
    "    print(f\"Processing weather sensitivity for {len(all_households)} households...\")\n",
    "    \n",
    "    for i, icp in enumerate(all_households):\n",
    "        house_data = daily_merged[daily_merged['ICP_IDENTIFIER'] == icp].copy()\n",
    "        \n",
    "        # Weather variables for analysis\n",
    "        temp_avg = house_data['daily_temp_avg']\n",
    "        energy = house_data['daily_total_kWh']\n",
    "        \n",
    "        # Temperature sensitivity analysis\n",
    "        temp_correlation = np.corrcoef(temp_avg, energy)[0, 1] if len(temp_avg) > 1 else 0\n",
    "        \n",
    "        # Heating patterns (using calculated thresholds)\n",
    "        cold_days = house_data[temp_avg < cold_threshold]  # Cold days\n",
    "        mild_days = house_data[(temp_avg >= cold_threshold) & (temp_avg <= warm_threshold)]  # Mild days\n",
    "        \n",
    "        cold_avg_energy = cold_days['daily_total_kWh'].mean() if len(cold_days) > 0 else 0\n",
    "        mild_avg_energy = mild_days['daily_total_kWh'].mean() if len(mild_days) > 0 else 0\n",
    "        \n",
    "        # Weather sensitivity score\n",
    "        heating_sensitivity = (cold_avg_energy - mild_avg_energy) if mild_avg_energy > 0 else 0\n",
    "        \n",
    "        # Seasonal patterns (month-based)\n",
    "        house_data['month'] = pd.to_datetime(house_data['DATE']).dt.month\n",
    "        \n",
    "        # Winter (Jun-Aug), Spring (Sep-Nov), Summer (Dec-Feb), Autumn (Mar-May)\n",
    "        winter_months = [6, 7, 8]\n",
    "        spring_months = [9, 10, 11] \n",
    "        summer_months = [12, 1, 2]\n",
    "        autumn_months = [3, 4, 5]\n",
    "        \n",
    "        winter_energy = house_data[house_data['month'].isin(winter_months)]['daily_total_kWh'].mean()\n",
    "        spring_energy = house_data[house_data['month'].isin(spring_months)]['daily_total_kWh'].mean()\n",
    "        summer_energy = house_data[house_data['month'].isin(summer_months)]['daily_total_kWh'].mean()\n",
    "        autumn_energy = house_data[house_data['month'].isin(autumn_months)]['daily_total_kWh'].mean()\n",
    "        \n",
    "        # Seasonal variability\n",
    "        seasonal_energies = [winter_energy, spring_energy, summer_energy, autumn_energy]\n",
    "        seasonal_energies = [x for x in seasonal_energies if not np.isnan(x)]\n",
    "        seasonal_range = (max(seasonal_energies) - min(seasonal_energies)) if len(seasonal_energies) > 1 else 0\n",
    "        \n",
    "        # Store weather sensitivity features \n",
    "        weather_features.append({\n",
    "            'ICP_IDENTIFIER': icp,\n",
    "            \n",
    "            # Core temperature sensitivity (most important)\n",
    "            'temperature_correlation': temp_correlation,\n",
    "            'heating_sensitivity_kWh': heating_sensitivity,\n",
    "            'seasonal_range_kWh': seasonal_range,\n",
    "            \n",
    "            # Energy consumption patterns\n",
    "            'cold_days_avg_kWh': cold_avg_energy,\n",
    "            \n",
    "            # Data quality check\n",
    "            'weather_analysis_days': len(house_data)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(weather_features)\n",
    "\n",
    "# Calculate weather sensitivity features\n",
    "weather_sensitivity_features = calculate_weather_sensitivity_features(df, time_cols_energy_only)\n",
    "\n",
    "# Merge with existing features - only power metrics\n",
    "complete_features = features_step1.merge(\n",
    "    weather_sensitivity_features, \n",
    "    on='ICP_IDENTIFIER', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\nWeather Sensitivity Summary\")\n",
    "print(f\"Weather features calculated for {len(weather_sensitivity_features)} households\")\n",
    "\n",
    "# Weather sensitivity insights\n",
    "if len(weather_sensitivity_features) > 0:\n",
    "    print(f\"\\nTemperature Correlation Range: {weather_sensitivity_features['temperature_correlation'].min():.3f} to {weather_sensitivity_features['temperature_correlation'].max():.3f}\")\n",
    "    print(f\"Heating Sensitivity Range: {weather_sensitivity_features['heating_sensitivity_kWh'].min():.2f} to {weather_sensitivity_features['heating_sensitivity_kWh'].max():.2f} kWh\")\n",
    "    print(f\"Seasonal Variability Range: {weather_sensitivity_features['seasonal_range_kWh'].min():.2f} to {weather_sensitivity_features['seasonal_range_kWh'].max():.2f} kWh\")\n",
    "\n",
    "    # Identify weather-sensitive vs weather-stable accommodations\n",
    "    high_temp_sensitivity = (abs(weather_sensitivity_features['temperature_correlation']) > 0.3).sum()\n",
    "    high_seasonal_variation = (weather_sensitivity_features['seasonal_range_kWh'] > weather_sensitivity_features['seasonal_range_kWh'].median()).sum()\n",
    "\n",
    "    print(f\"\\nWeather Sensitivity Patterns:\")\n",
    "    print(f\"  High temperature sensitivity (|corr| > 0.3): {high_temp_sensitivity} accommodations ({high_temp_sensitivity/len(weather_sensitivity_features)*100:.1f}%)\")\n",
    "    print(f\"  High seasonal variation: {high_seasonal_variation} accommodations ({high_seasonal_variation/len(weather_sensitivity_features)*100:.1f}%)\")\n",
    "\n",
    "# Save complete features with weather sensitivity\n",
    "features_step2 = complete_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Time Pattern Features\n",
      "Processing time patterns...\n",
      "Found 48 half-hourly columns\n",
      "Time period definitions:\n",
      "  Night (Sleep): 11pm-6am\n",
      "  Morning: 6am-10am\n",
      "  Daytime: 10am-5pm\n",
      "  Evening: 5pm-11pm\n",
      "Processing time patterns for 118 households...\n",
      "\n",
      "TIME PATTERN SUMMARY\n",
      "Time features calculated for 118 households\n",
      "\n",
      "Time Energy Distribution:\n",
      "  Night energy: 25.2% ± 4.9%\n",
      "  Morning energy: 15.4% ± 1.8%\n",
      "  Daytime energy: 28.9% ± 4.3%\n",
      "  Evening energy: 30.5% ± 2.3%\n",
      "\n",
      "Behavioral Patterns:\n",
      "  Daily consistency (CV): 0.667 ± 0.150\n",
      "  Weekday/Weekend ratio: 1.02 ± 0.05\n",
      "  Usage concentration: 0.022 ± 0.002\n"
     ]
    }
   ],
   "source": [
    "# Time Pattern Features \n",
    "print(\"Calculating Time Pattern Features\")\n",
    "\n",
    "def calculate_time_pattern_features(df):\n",
    "   \n",
    "    print(\"Processing time patterns...\")\n",
    "    \n",
    "    # Data is in wide format \n",
    "    # Use existing DATETIME column\n",
    "    df['datetime'] = pd.to_datetime(df['DATETIME'])\n",
    "    df['date'] = df['datetime'].dt.date\n",
    "    df['dayofweek'] = df['datetime'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "    df['is_weekend'] = df['dayofweek'].isin([5, 6])  # Saturday, Sunday\n",
    "    \n",
    "    # Get all half-hourly columns (48 periods)\n",
    "    half_hourly_cols = [col for col in df.columns if '.' in col and '-' in col]\n",
    "    print(f\"Found {len(half_hourly_cols)} half-hourly columns\")\n",
    "    \n",
    "    # Define time periods by mapping half-hourly columns to periods\n",
    "    def get_time_period_cols():\n",
    "        night_cols = []    # 11pm-6am (23:00-06:00)\n",
    "        morning_cols = []  # 6am-10am  (06:00-10:00)  \n",
    "        daytime_cols = []  # 10am-5pm  (10:00-17:00)\n",
    "        evening_cols = []  # 5pm-11pm  (17:00-23:00)\n",
    "        \n",
    "        for col in half_hourly_cols:\n",
    "            # Extract start hour from column name \n",
    "            start_time = col.split('-')[0]\n",
    "            hour = int(start_time.split('.')[0])\n",
    "            \n",
    "            if hour >= 23 or hour < 6:  # 11pm-6am\n",
    "                night_cols.append(col)\n",
    "            elif 6 <= hour < 10:  # 6am-10am\n",
    "                morning_cols.append(col)\n",
    "            elif 10 <= hour < 17:  # 10am-5pm\n",
    "                daytime_cols.append(col)\n",
    "            elif 17 <= hour < 23:  # 5pm-11pm\n",
    "                evening_cols.append(col)\n",
    "        \n",
    "        return night_cols, morning_cols, daytime_cols, evening_cols\n",
    "    \n",
    "    night_cols, morning_cols, daytime_cols, evening_cols = get_time_period_cols()\n",
    "    \n",
    "    print(\"Time period definitions:\")\n",
    "    print(\"  Night (Sleep): 11pm-6am\")\n",
    "    print(\"  Morning: 6am-10am\") \n",
    "    print(\"  Daytime: 10am-5pm\")\n",
    "    print(\"  Evening: 5pm-11pm\")\n",
    "    \n",
    "    # Calculate features for each household\n",
    "    all_households = df['ICP_IDENTIFIER'].unique()\n",
    "    time_features = []\n",
    "    \n",
    "    print(f\"Processing time patterns for {len(all_households)} households...\")\n",
    "    \n",
    "    for i, icp in enumerate(all_households):\n",
    "        house_data = df[df['ICP_IDENTIFIER'] == icp].copy()\n",
    "        \n",
    "        # Convert half-hourly kW values back to kWh for time pattern analysis\n",
    "        half_hourly_kwh = house_data[half_hourly_cols] / 2\n",
    "        \n",
    "        # Calculate time-of-day energy consumption by summing relevant half-hourly columns\n",
    "        night_consumption = half_hourly_kwh[[col for col in half_hourly_cols if col in night_cols]].sum(axis=1).sum()\n",
    "        morning_consumption = half_hourly_kwh[[col for col in half_hourly_cols if col in morning_cols]].sum(axis=1).sum()\n",
    "        daytime_consumption = half_hourly_kwh[[col for col in half_hourly_cols if col in daytime_cols]].sum(axis=1).sum()\n",
    "        evening_consumption = half_hourly_kwh[[col for col in half_hourly_cols if col in evening_cols]].sum(axis=1).sum()\n",
    "        \n",
    "        total_consumption = night_consumption + morning_consumption + daytime_consumption + evening_consumption\n",
    "        \n",
    "        # Calculate ratios \n",
    "        night_ratio = (night_consumption / total_consumption) if total_consumption > 0 else 0\n",
    "        morning_ratio = (morning_consumption / total_consumption) if total_consumption > 0 else 0\n",
    "        daytime_ratio = (daytime_consumption / total_consumption) if total_consumption > 0 else 0\n",
    "        evening_ratio = (evening_consumption / total_consumption) if total_consumption > 0 else 0\n",
    "        \n",
    "        # Daily consumption consistency using Total_Consumption column (kWh)\n",
    "        daily_totals = house_data['Total_Consumption']\n",
    "        daily_mean = daily_totals.mean()\n",
    "        daily_std = daily_totals.std()\n",
    "        daily_consistency = (daily_std / daily_mean) if daily_mean > 0 else 0\n",
    "        \n",
    "        # Weekday vs Weekend patterns (using Total_Consumption kWh)\n",
    "        weekday_avg = house_data[~house_data['is_weekend']]['Total_Consumption'].mean()\n",
    "        weekend_avg = house_data[house_data['is_weekend']]['Total_Consumption'].mean()\n",
    "        weekday_weekend_ratio = (weekday_avg / weekend_avg) if weekend_avg > 0 else 0\n",
    "        \n",
    "        # Usage concentration across 48 half-hourly periods (using kWh)\n",
    "        half_hourly_avgs = half_hourly_kwh.mean()\n",
    "        total_avg = half_hourly_avgs.sum()\n",
    "        half_hourly_ratios = half_hourly_avgs / total_avg if total_avg > 0 else pd.Series([0]*len(half_hourly_cols))\n",
    "        usage_concentration = (half_hourly_ratios ** 2).sum()\n",
    "        \n",
    "        # Get total days for data quality tracking\n",
    "        total_days = len(daily_totals)\n",
    "        \n",
    "        # Store time pattern features\n",
    "        time_features.append({\n",
    "            'ICP_IDENTIFIER': icp,\n",
    "            \n",
    "            # Time-of-day patterns (4 features)\n",
    "            'night_usage_ratio': night_ratio,\n",
    "            'morning_usage_ratio': morning_ratio,\n",
    "            'daytime_usage_ratio': daytime_ratio,\n",
    "            'evening_usage_ratio': evening_ratio,\n",
    "            \n",
    "            # Behavioral consistency (2 features)\n",
    "            'daily_usage_consistency': daily_consistency,\n",
    "            'weekday_weekend_ratio': weekday_weekend_ratio,\n",
    "            \n",
    "            # Advanced patterns (1 feature)\n",
    "            'usage_concentration': usage_concentration,\n",
    "            \n",
    "            # Data quality\n",
    "            'time_analysis_days': total_days\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(time_features)\n",
    "\n",
    "# Calculate time pattern features\n",
    "time_pattern_features = calculate_time_pattern_features(df)\n",
    "\n",
    "print(f\"\\nTIME PATTERN SUMMARY\")\n",
    "print(f\"Time features calculated for {len(time_pattern_features)} households\")\n",
    "\n",
    "# Time pattern insights\n",
    "if len(time_pattern_features) > 0:\n",
    "    print(f\"\\nTime Energy Distribution:\")\n",
    "    print(f\"  Night energy: {time_pattern_features['night_usage_ratio'].mean():.1%} ± {time_pattern_features['night_usage_ratio'].std():.1%}\")\n",
    "    print(f\"  Morning energy: {time_pattern_features['morning_usage_ratio'].mean():.1%} ± {time_pattern_features['morning_usage_ratio'].std():.1%}\")\n",
    "    print(f\"  Daytime energy: {time_pattern_features['daytime_usage_ratio'].mean():.1%} ± {time_pattern_features['daytime_usage_ratio'].std():.1%}\")\n",
    "    print(f\"  Evening energy: {time_pattern_features['evening_usage_ratio'].mean():.1%} ± {time_pattern_features['evening_usage_ratio'].std():.1%}\")\n",
    "    \n",
    "    print(f\"\\nBehavioral Patterns:\")\n",
    "    print(f\"  Daily consistency (CV): {time_pattern_features['daily_usage_consistency'].mean():.3f} ± {time_pattern_features['daily_usage_consistency'].std():.3f}\")\n",
    "    print(f\"  Weekday/Weekend ratio: {time_pattern_features['weekday_weekend_ratio'].mean():.2f} ± {time_pattern_features['weekday_weekend_ratio'].std():.2f}\")\n",
    "    print(f\"  Usage concentration: {time_pattern_features['usage_concentration'].mean():.3f} ± {time_pattern_features['usage_concentration'].std():.3f}\")\n",
    "    \n",
    "    features_step3 = time_pattern_features.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CALCULATING ROOM-NORMALIZED FEATURES ===\n",
      "Processing room-normalized consumption patterns...\n",
      "Room distribution: {1: 2, 2: 13, 3: 8, 4: 24, 5: 37, 6: 31, 7: 1, 9: 1, 11: 1}\n",
      "Processed 100/118 households...\n",
      "Merging room-normalized features with existing features...\n",
      "\n",
      "ROOM-NORMALIZED SUMMARY\n",
      "\n",
      " Final complete feature set saved to 'final_features.csv'\n",
      "Total features: 25\n",
      "Total households: 118\n"
     ]
    }
   ],
   "source": [
    "# Room-Normalized Features\n",
    "print(\"=== CALCULATING ROOM-NORMALIZED FEATURES ===\")\n",
    "\n",
    "def calculate_room_normalized_features(df):\n",
    "    \"\"\"Calculate per-room consumption and efficiency metrics for each household\"\"\"\n",
    "    \n",
    "    print(\"Processing room-normalized consumption patterns...\")\n",
    "    \n",
    "    # Get room information for each household\n",
    "    room_info = df.groupby('ICP_IDENTIFIER')['Rooms'].first().reset_index()\n",
    "    print(f\"Room distribution: {room_info['Rooms'].value_counts().sort_index().to_dict()}\")\n",
    "    \n",
    "    # Calculate room-normalized features for each household\n",
    "    all_households = df['ICP_IDENTIFIER'].unique()\n",
    "    room_features = []\n",
    "    \n",
    "    # Get all half-hourly columns \n",
    "    half_hourly_cols = [col for col in df.columns if '.' in col and '-' in col and col != 'INTERVAL_DATE']\n",
    "    \n",
    "    for i, icp in enumerate(all_households):\n",
    "        house_data = df[df['ICP_IDENTIFIER'] == icp].copy()\n",
    "        \n",
    "        # Get room count\n",
    "        rooms = max(house_data['Rooms'].iloc[0], 1)  # Avoid division by zero\n",
    "        \n",
    "        # 1. Average power per room (kW/room) - baseline energy intensity\n",
    "        avg_power_per_room = house_data[half_hourly_cols].mean().mean() / rooms\n",
    "        \n",
    "        # 2. Peak power per room (kW/room) - maximum demand capacity\n",
    "        daily_peaks = house_data.groupby('INTERVAL_DATE')[half_hourly_cols].max().max(axis=1)\n",
    "        peak_power_per_room = daily_peaks.mean() / rooms\n",
    "        \n",
    "        # 3. Power variability per room (CV) - usage pattern consistency\n",
    "        daily_avg_power = house_data.groupby('INTERVAL_DATE')[half_hourly_cols].mean().mean(axis=1)\n",
    "        daily_power_per_room = daily_avg_power / rooms\n",
    "        power_variability_per_room = (daily_power_per_room.std() / avg_power_per_room) if avg_power_per_room > 0 else 0\n",
    "        \n",
    "        # Store the essential room-normalised features\n",
    "        room_features.append({\n",
    "            'ICP_IDENTIFIER': icp,\n",
    "            'rooms': rooms,\n",
    "            \n",
    "            # Core room-normalised features (3 features)\n",
    "            'avg_power_per_room': avg_power_per_room,\n",
    "            'peak_power_per_room': peak_power_per_room,\n",
    "            'power_variability_per_room': power_variability_per_room\n",
    "        })\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(all_households)} households...\")\n",
    "    \n",
    "    room_features_df = pd.DataFrame(room_features)\n",
    "\n",
    "    # Merge with existing features\n",
    "    print(\"Merging room-normalized features with existing features...\")\n",
    "    \n",
    "    # Start with weather features as base\n",
    "    complete_features = features_step2.copy()\n",
    "    \n",
    "    # Add time pattern features \n",
    "    complete_features = complete_features.merge(\n",
    "        features_step3[['ICP_IDENTIFIER'] + [col for col in features_step3.columns if col != 'ICP_IDENTIFIER']], \n",
    "        on='ICP_IDENTIFIER', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Add room-normalised features (excluding rooms and ICP_IDENTIFIER)\n",
    "    room_feature_cols = ['ICP_IDENTIFIER', 'avg_power_per_room', 'peak_power_per_room', 'power_variability_per_room']\n",
    "    complete_features = complete_features.merge(\n",
    "        room_features_df[room_feature_cols], \n",
    "        on='ICP_IDENTIFIER', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    return room_features_df, complete_features\n",
    "\n",
    "# Calculate room-normalised features\n",
    "room_features, final_complete_features = calculate_room_normalized_features(df)\n",
    "\n",
    "print(f\"\\nROOM-NORMALIZED SUMMARY\")\n",
    "\n",
    "# Round all numeric columns to 2 decimals\n",
    "numeric_cols = final_complete_features.select_dtypes(include=[np.number]).columns\n",
    "final_complete_features[numeric_cols] = final_complete_features[numeric_cols].round(2)\n",
    "\n",
    "# Save complete feature set with a clean name\n",
    "final_complete_features.to_csv('final_features.csv', index=False)\n",
    "print(f\"\\n Final complete feature set saved to 'final_features.csv'\")\n",
    "print(f\"Total features: {len(final_complete_features.columns) - 1}\")\n",
    "print(f\"Total households: {len(final_complete_features)}\")  # -1 for ICP_IDENTIFIER\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
